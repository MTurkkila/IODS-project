# Regression and model validation
I started with the Datacamp and afterwards th data wrangling was straightforward and easy. Thus I used the data file from my local folder in the analysis. Below are the important parts of the script. Before any analysis,  ggplot2 and GGally libraries are accessed first as is the common practice.
```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(GGally)
```
Read the data from a local folder and check for structure and dimensions
```{r}
students2014 <- read.table("data/students2014.txt", sep="\t")
str(students2014)
dim(students2014)
```
The Data has 7 variables and 166 observations from a questionnaire. Variables deep, stra and surf are sum variables scaled to the original scale. The data only includes observations with points over 0.

Next I use the ggpair-function to show graphical overview of the data. In the actual script, I also save the plots in a local folder *plots* with dev.copy()-function.
```{r}
p <- ggpairs(students2014, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
p
```

In addition to plotting the dataframe, I checked the summaries of the data.
```{r}
summary(students2014)
```
As attitude, stra and surf have the highest absolute correlation with points I chose those for the initial linear model and created a regression model with multiple explanatory variables and print the summary of my model.
```{r}
my_model <- lm(Points ~ Attitude + stra + surf, data = students2014)
summary(my_model)
```
The summary shows estimations for the parameters of the linear model and the statistical significance for those estimates. Only attitude is statistically significant (shown with the stars) and therefore I only include it to the second model
```{r}
my_model2 <- lm(Points ~ Attitude, data = students2014)
summary(my_model2)
```
The summaries show that now both $\alpha$ and $\beta$ variables are highly statistically significant. The estimates show that attitude has positive correlation with the attitude i.e. more positive attitude yields more points.

The multiple R squared shows how much of the variation in the points is explains by the attitude. In this model, it is 19%

Check for validity with diagnostic plots
```{r}
par(mfrow = c(2,2))
plot(my_model2, which = c(1, 2, 5))
```

The model assumes that errors are normally distributed, are not correlated and have constant variance.

* Residuals vs Fitted: Points are spread quite randomly, so constant variance assumption seems reasonable.
* Normal Q-Q: There are some deviations form the line at low and high quantiles, so the normality assumption might be questionable. However, most points fit very nicely to the line.
* Residuals vs Leverage: No single observation stand out.

Overall, I'd say the model is quite reasonable.